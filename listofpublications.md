# Papers related to NVRAM
--------------------------------------------------

|Conference| Title   |     Link     |Broad category|  Abstract |
|:-------|:----------|:-------------:|:--------|:------|
|ISCA 2014| A low power and reliable charge pump design for Phase Change Memories |  [link](https://ieeexplore.ieee.org/document/6853222/) |Architecture(NVRAM)|Emerging nonvolatile memory technologies (NVRAM) promise the performance of DRAM with the persistence of disk. However, constraining NVRAM write order, necessary to ensure recovery correctness, limits NVRAM write concurrency and degrades throughput. We require new memory interfaces to minimally describe write constraints and allow high performance and high concurrency data structures. These goals strongly resemble memory consistency. Whereas memory consistency concerns the order that memory operations are observed between numerous processors, persistent memory systems must constrain the order that writes occur with respect to failure. We introduce memory persistency, a new approach to designing persistent memory interfaces, building on memory consistency. Similar to memory consistency, memory persistency models may be relaxed to improve performance. We describe the design space of memory persistency and desirable features that such a memory system requires. Finally, we introduce several memory persistency models and evaluate their ability to expose NVRAM write concurrency using two implementations of a persistent queue. Our results show that relaxed persistency models accelerate system throughput 30-fold by reducing NVRAM write constraints.|
|ISCA 2017|Viyojit: Decoupling battery and DRAM capacities for battery-backed DRAM|[link](https://ieeexplore.ieee.org/document/8192506/)|Architecture(NVM)|Non-Volatile Memories (NVMs) can significantly improve the performance of data-intensive applications. A popular form of NVM is Battery-backed DRAM, which is available and in use today with DRAMs latency and without the endurance problems of emerging NVM technologies. Modern servers can be provisioned with up-to 4 TB of DRAM, and provisioning battery backup to write out such large memories is hard because of the large battery sizes and the added hardware and cooling costs. We present Viyojit, a system that exploits the skew in write working sets of applications to provision substantially smaller batteries while still ensuring durability for the entire DRAM capacity. Viyojit achieves this by bounding the number of dirty pages in DRAM based on the provisioned battery capacity and proactively writing out infrequently written pages to an SSD. Even for write-heavy workloads with less skew than we observe in analysis of real data center traces, Viyojit reduces the required battery capacity to 11% of the original size, with a performance overhead of 7-25%. Thus, Viyojit frees battery-backed DRAM from stunted growth of battery capacities and enables servers with terabytes of battery-backed DRAM.|
|ISCA 2018| 2B-SSD: The Case for Dual, Byte- and Block-Addressable Solid-State Drives |[link](https://ieeexplore.ieee.org/document/8416845/)|Architecture(NVRAM)|Performance critical transaction and storage systems require fast persistence of write data. Typically, a non-volatile RAM (NVRAM) is employed on the datapath to the permanent storage, to temporarily and quickly store write data before the system acknowledges the write request. NVRAM is commonly implemented with battery-backed DRAM. Unfortunately, battery-backed DRAM is small and costly, and occupies a precious DIMM slot. In this paper, we make a case for dual, byte- and block-addressable solid-state drive (2B-SSD), a novel NAND flash SSD architecture designed to offer a dual view of byte addressability and traditional block addressability at the same time. Unlike a conventional storage device, 2B-SSD allows accessing the same file with two independent byte- and block-I/O paths. It controls the data transfer between its internal DRAM and NAND flash memory through an intuitive software interface, and manages the mapping of the two address spaces. 2B-SSD realizes a wholly different way and speed of accessing files on a storage device; applications can access them directly using memory-mapped I/O, and moreover write with a DRAM-like latency. To quantify the benefits of 2B-SSD, we modified logging subsystems of major database engines to store log records directly on it without buffering them in the host memory. When running popular workloads, we measured throughput gains in the range of 1.2X and 2.8X with no risk of data loss.|
|MICRO 2014|FIRM: Fair and High-Performance Memory Control for Persistent Memory Systems|[link](https://ieeexplore.ieee.org/document/7011385/) |Architecture(NVM)|Byte-addressable nonvolatile memories promise a new technology, persistent memory, which incorporates desirable attributes from both traditional main memory (byte-addressability and fast interface) and traditional storage (data persistence). To support data persistence, a persistent memory system requires sophisticated data duplication and ordering control for write requests. As a result, applications that manipulate persistent memory (persistent applications) have very different memory access characteristics than traditional (non-persistent) applications, as shown in this paper. Persistent applications introduce heavy write traffic to contiguous memory regions at a memory channel, which cannot concurrently service read and write requests, leading to memory bandwidth underutilization due to low bank-level parallelism, frequent write queue drains, and frequent bus turnarounds between reads and writes. These characteristics undermine the high-performance and fairness offered by conventional memory scheduling schemes designed for non-persistent applications. Our goal in this paper is to design a fair and high-performance memory control scheme for a persistent memory based system that runs both persistent and non-persistent applications. Our proposal, FIRM, consists of three key ideas. First, FIRM categorizes request sources as non-intensive, streaming, random and persistent, and forms batches of requests for each source. Second, FIRM strides persistent memory updates across multiple banks, thereby improving bank-level parallelism and hence memory bandwidth utilization of persistent memory accesses. Third, FIRM schedules read and write request batches from different sources in a manner that minimizes bus turnarounds and write queue drains. Our detailed evaluations show that, compared to five previous memory scheduler designs, FIRM provides significantly higher system performance and fairness.|
|HPCA 2018|Crash Consistency in Encrypted Non-volatile Main Memory Systems| [link](https://ieeexplore.ieee.org/document/8327018/)|Architecture(NVM)|Non-Volatile Main Memory (NVMM) systems provide high performance by directly manipulating persistent data in-memory, but require crash consistency support to recover data in a consistent state in case of a power failure or system crash. In this work, we focus on the interplay between the crash consistency mechanisms and memory encryption. Memory encryption is necessary for these systems to protect data against the attackers with physical access to the persistent main memory. As decrypting data at every memory read access can significantly degrade the performance, prior works propose to use a memory encryption technique, counter-mode encryption, that reduces the decryption overhead by performing a memory read access in parallel with the decryption process using a counter associated with each cache line. Therefore, a pair of data and counter value is needed to correctly decrypt data after a system crash. We demonstrate that counter-mode encryption does not readily extend to crash consistent NVMM systems as the system will fail to recover data in a consistent state if the encrypted data and associated counter are not written back to memory atomically, a requirement we refer to as counter-atomicity. We show that naively enforcing counter-atomicity for all NVMM writes can serialize memory accesses and results in a significant performance degradation. In order to improve the performance, we make an observation that not all writes to NVMM need to be counter-atomic. The crash consistency mechanisms rely on versioning to keep one consistent copy of data intact while manipulating another version directly in-memory. As the recovery process only relies on the unmodified consistent version, it is not necessary to strictly enforce counter-atomicity for the writes that do not affect data recovery. Based on this insight, we propose selective counter-atomicity that allows reordering of writes to data and associated counters when the writes to persistent memory do not alter the recoverable consistent state. We propose efficient software and hardware support to enforce selective counter-atomicity. Our evaluation demonstrates that in a 1/2/4/8- core system, selective counter-atomicity improves performance by 6/11/22/40% compared to a system that enforces counter-atomicity for all NVMM writes. The performance of our selective counter-atomicity design comes within 5% of an ideal NVMM system that |provides crash consistency of encrypted data at no cost.|
|HPCA 2016|Atomic persistence for SCM with a non-intrusive backend controller|[link](https://ieeexplore.ieee.org/document/7446055/)|Architecture(NVM)-Software Interface|Non-volatile byte-addressable memory has the potential to revolutionize system architecture by providing instruction-grained direct access to vast amounts of persistent data. We describe a non-intrusive memory controller that uses backend operations for achieving lightweight failure atomicity. By moving synchronous persistent memory operations to the background, the performance overheads are minimized. Our solution avoids costly software intervention by decoupling isolation and concurrency-driven atomicity from failure atomicity and durability, and does not require changes to the front-end cache hierarchy. Two implementation alternatives - one using a hardware structure, and the other extending the memory controller with a firmware managed volatile space - are described. Our results show the performance is significantly better than traditional approaches.|
|ASPLOS '16| NVWAL: Exploiting NVRAM in Write-Ahead Logging|[link](https://dl.acm.org/citation.cfm?id=2872392)|Architecture(NVRAM)Software Interface| Emerging byte-addressable non-volatile memory is considered an alternative storage device for database logs that require persistency and high performance. In this work, we develop NVWAL (NVRAM Write-Ahead Logging) for SQLite. The contribution of NVWAL consists of three elements: (i) byte-granularity differential logging that effectively eliminates the excessive I/O overhead of filesystem-based logging or journaling, (ii) transaction-aware lazy synchronization that reduces cache synchronization overhead by two-thirds, and (iii) user-level heap management of the NVRAM persistent WAL structure, which reduces the overhead of managing persistent objects. We implemented NVWAL in SQLite and measured the performance on a Nexus 5 smartphone and an NVRAM emulation board - Tuna. Our performance study shows the following: (i) the overhead of enforcing strict ordering of NVRAM writes can be reduced via NVRAM-aware transaction management. (ii) From the application performance point of view, the overhead of guaranteeing failure atomicity is negligible; the cache line flush overhead accounts for only 0.8~4.6% of transaction execution time. Therefore, application performance is much less sensitive to the NVRAM performance than we expected. Decreasing the NVRAM latency by one-fifth (from 1942 nsec to 437 nsec), SQLite achieves a mere 4% performance gain (from 2517 ins/sec to 2621 ins/sec). (iii) Overall, when the write latency of NVRAM is 2 usec, NVWAL increases SQLite performance by at least 10x compared to that of WAL on flash memory (from 541 ins/sec to 5812 ins/sec).|
|DAC 18| Enabling union page cache to boost file access performance of NVRAM-based storage device| [link](https://dl.acm.org/citation.cfm?id=3196045)|Archtecture(NVM)OS Interface|Due to the fast access performance, byte-addressability, and non-volatility of non-volatile random access memory (NVRAM), NVRAM has emerged as a popular candidate for the design of memory/storage systems on mobile computing systems. For example, the latest 3D xPoint memory could be a kind of NVRAM with much longer life expectancy than NAND flash and could ease the possible endurance issue. When NVRAM is considered as both main memory and storage in mobile computing systems, existing page cache mechanisms introduce too many unnecessary data movements between main memory and storage. To resolve this issue, we propose the concept of "union page cache," which jointly manages data of the page cache in both main memory and storage. To realize this concept, a partial page cache strategy is designed to consider both main memory and storage as its management space and to eliminate unnecessary data movements between main memory and storage without sacrificing the data consistency of file systems. Experimental results show that the proposed strategy can boost the file accessing performance upto 85.62% when using PCM as a case study.|
|VLDB 2015|nvm malloc: Memory Allocation for NVRAM|[link](http://www.adms-conf.org/2015/adms15_schwalb.pdf)|Architecture(NVRAM)OS Interface|Non-volatile main memory (NVRAM) has the potential to fundamentally change the persistency of software. Applications can make their state persistent by directly placing data structures on NVRAM instead of volatile DRAM. However, the persistent nature of NVRAM requires significant changes for memory allocators that are now faced with the additional tasks of data recovery and failure-atomicity. In this paper, we present nvm malloc, a general-purpose memory allocator concept for the NVRAM era as a basic building block for persistent applications. We introduce concepts for managing named allocations for simplified recovery and using volatile and non-volatile memory in combination to provide both high performance and failure-atomic allocations.|
|IEEE Transactions on Consumer Electronics(2012)|Efficient logging of metadata using NVRAM for NAND flash based file system|[link](https://ieeexplore.ieee.org/abstract/document/6170059/)|Software Interface|In this work, we designed and implemented schemes that defer writing of metadata in order to realize an efficient and reliable NAND flash file system. The conventional NAND flash file systems synchronously write their metadata in the NAND flash for reliability; however, the synchronous writing of metadata generates excessive garbage. We propose the scheme for merging the writing of metadata so as to reduce the garbage of the NAND flash while ensuring file system consistency. The proposed scheme uses the non-volatile memory for synchronously logging modifications of the metadata. The logging can significantly reduce excessive metadata writing of NAND flash. Also, the last modified metadata can be recovered from a crash, after scanning logs in the non-volatile memory. We implemented the scheme for the deferred writing of metadata on top of a Linux OS. The evaluation results show that the proposed scheme greatly reduced the overall application time and the number of written pages across various benchmarks, compared to the conventional flash file system.|
|NVMW 17|SECRET: Smartly EnCRypted Energy EfficienT Non-Volatile Memories|[link](https://ieeexplore.ieee.org/document/7544407/)|Architecture(Hardware)|Data persistence in emerging non-volatile memories (NVMs) poses a multitude of security vulnerabilities, motivating main memory encryption for data security. However, practical encryption algorithms demonstrate strong diffusion characteristics that increase cell flips, resulting in increased write energy/latency and reduced lifetime of NVMs. State-of-the-art security solutions have focused on reducing the encryption penalty (increased write energy/latency and reduced memory lifetime) in single-level cell (SLC) NVMs; however, the realization of low encryption penalty solutions for multi-/triple-level cell (MLC/TLC) secure NVMs remains an open area of research. This work synergistically integrates zero-based partial writes with XOR-based energy masking to realize Smartly EnCRypted Energy efficienT, i.e., SECRET MLC/TLC NVMs, without compromising the security of the underlying encryption technique. Our simulations on an MLC (TLC) resistive RAM (RRAM) architecture across SPEC CPU2006 workloads demonstrate that for 6.25% (7.84%) memory overhead, SECRET reduces write energy by 80% (63%), latency by 37% (49%), and improves memory lifetime by 63% (56%) over conventional advanced encryption standard-based (AES-based) counter mode encryption.|
|NVMW 17|NVQuery: Efficient Query Processing in Non-Volatile Memory|[link](https://ieeexplore.ieee.org/document/8323230/)|NVM In memory processing|Today’s computing systems use huge amount of energy and time to process basic queries in database. A large part of it is spent in data movement between the memory and processing cores, owing to the limited cache capacity and memory bandwidth of traditional computers. In this paper, we propose a non-volatile memory-based query accelerator, called NVQuery, which performs several basic query functions in memory including aggregation, prediction, bit-wise operations, join operations, as well as exact and nearest distance search queries. NVQuery is implemented on a content addressable memory (CAM) and exploits the analog characteristic of non-volatile memory in order to enable in-memory processing. To implement nearest distance search in memory, we introduce a novel bitline driving scheme to give weights to the indices of the bits during the search operation. To further improve the energy efficiency, our design supports configurable approximation by adaptively putting memory blocks under voltage overscaling. Our experimental evaluation shows that, NVQuery can provide 49.3× performance speedup and 32.9× energy savings as compared to running the same query on traditional processor. Approximation improves the energy-delay product of NVQuery by 7.3×, while providing acceptable accuracy. In addition, NVQuery can achieve 30.1× energy-delay product improvement as compared to the state-of-the-art query accelerators.|
|NVMW 16|NOVA: A Log-structured File System for Hybrid Volatile/Non-volatile Main Memories|[link](https://www.usenix.org/system/files/conference/fast16/fast16-papers-xu.pdf)|NVM OS Interface|NOVA is a log-structured file system for hybrid volatile/non-volatile main memories. NOVA extends LFS to leverage NVMM, yielding a simpler, high-performance file system that supports fast and efficient garbage collection and quick recovery from system failures. NOVA outperforms existing file systems by a wide margin on a wide range of applications while providing stronger consistency and atomicity guarantees.|
|FAST 15|NV-Tree: Reducing Consistency Cost for NVM-based Single Level Systems|[link](https://www.usenix.org/conference/fast15/technical-sessions/presentation/yang)|Architecture(NVM)|The non-volatile memory (NVM) has DRAM-like performance and disk-like persistency which make it possible to replace both disk and DRAM to build single level systems. To keep data consistency in such systems is non-trivial because memory writes may be reordered by CPU and memory controller. In this paper, we study the consistency cost for an important and common data structure, B+Tree. Although the memory fence and CPU cacheline flush instructions can order memory writes to achieve data consistency, they introduce a significant overhead (more than 10X slower in performance). Based on our quantitative analysis of consistency cost, we propose NV-Tree, a consistent and cache-optimized B+Tree variant with reduced CPU cacheline flush. We implement and evaluate NV-Tree and NV-Store, a key-value store based on NV-Tree, on an NVDIMM server. NVTree outperforms the state-of-art consistent tree structures by up to 12X under write-intensive workloads. NV-Store increases the throughput by up to 4.8X under YCSB workloads compared to Redis.|
|DAC 2017|A Novel ReRAM-Based Main Memory Structure for Optimizing Access Latency and Reliability|[link](https://dl.acm.org/citation.cfm?id=3062191)|Architecture(NVRAM)Hardware|Emerging Resistive Memory (ReRAM) is a promising candidate as the replacement for DRAM because of its low power consumption, high density and high endurance. Due to the unique crossbar structure, ReRAM can be constructed with a very high density. However, ReRAM's crossbar structure causes an IR drop problem which results in non-uniform access latency in ReRAM banks and reduces its reliability. Besides, the access latency and reliability of ReRAM arrays are greatly influenced by the data patterns involved in a write operation. In this paper, we propose a performance and reliability efficient ReRAM-based main memory structure. At the circuit level, we propose a double-sided write driver design to reduce the IR drops along bitlines. At the architecture level, a region partition with address remapping method and two flip schemes are proposed to reduce the access latency and improve the reliability of ReRAM arrays. The experimental results show that the proposed design can improve the system performance by 30.3% on average and reduce the memory access latency by 25.9% on average over an aggressive baseline, meanwhile the design improves the reliability of ReRAM-based memory system.|
|DAC 2016|Fine-Granularity Tile-Level Parallelism in Non-volatile Memory Architecture with Two-Dimensional Bank Subdivision|[link](https://ieeexplore.ieee.org/document/7544409/)|Architecture(NVRAM)|Emerging memory technologies such as phase-change memory (PCM) and resistive RAMs (RRAM) have been proposed as promising candidates for future DRAM replacements. Due to the nature of how these memories operate, unique properties (such as non-destructive read and current-sensing) can be exploited to further subdivide memory and provide increasing parallelism with negligible overhead. In this work, we leverage these properties to design a finegrained non-volatile memory (FgNVM), featuring two-dimensional bank subdivision for tile-level parallelism (TLP) in a NVM memory bank, with much finer-granularity and increased parallelism than the one-dimensional bank subdivision for subarray-level parallelism (SALP) in a DRAM memory bank. With such new tile-level parallelism, three new memory access modes are proposed for further performance improvement and energy reduction: Partial-Activation, Multi-Activation, and Background Writes. Our experimental results show that the new architecture is highly effective in boosting non-volatile memory performance with significant energy reduction. To the best of our knowledge, this is the first work to study fine-granularity memory access in emerging non-volatile memory architectures.|
|DAC 2016|Pinatubo: A processing-in-memory architecture for bulk bitwise operations in emerging non-volatile memories|[link](https://ieeexplore.ieee.org/document/7544414/)|In memory processing|Processing-in-memory (PIM) provides high bandwidth, massive parallelism, and high energy efficiency by implementing computations in main memory, therefore eliminating the overhead of data movement between CPU and memory. While most of the recent work focused on PIM in DRAM memory with 3D die-stacking technology, we propose to leverage the unique features of emerging non-volatile memory (NVM), such as resistance-based storage and current sensing, to enable efficient PIM design in NVM. We propose Pinatubo 1 , a Processing In Non-volatile memory ArchiTecture for bUlk Bitwise Operations. Instead of integrating complex logic inside the cost-sensitive memory, Pinatubo redesigns the read circuitry so that it can compute the bitwise logic of two or more memory rows very efficiently, and support one-step multi-row operations. The experimental results on data intensive graph processing and database applications show that Pinatubo achieves a ~500 x speedup, ~28000x energy saving on bitwise operations, and 1.12× overall speedup, 1.11× overall energy saving over the conventional processor.|
|NVMW 2015|A Reliable and Highly-Available Non-Volatile Memory System|[link](http://cseweb.ucsd.edu/~yiyingzhang/mojim-asplos15.pdf)|NVM Software Interface|Next-generation non-volatile memories can attach directly to processors to form non-volatile main memory (NVMM) and offer the opportunity to build very low latency storage systems. However, providing reliability and availability to NVMM is challenging, since the latency of data replication can squander the low latency that NVMM can provide. We propose Mojim, a system that provides the reliability and availability that large-scale storage systems require, while preserving the performance of NVMM.|
|NVMW 2015|Zero-Overhead NVM Crash Resilience|[link](https://pdfs.semanticscholar.org/50f2/83259801ffbd354aaf94228d3b48c19ee6ed.pdf)|NVM-Software Interface|Byte-addressable non-volatile memory (NVM) allows in-place update of durable data. NVM transaction mechanisms prevent failures during updates from corrupting data, but such mechanisms carry substantial performance overheads. Our new alternative for high-performance multi-threaded software guarantees consistent recovery of application data following failure and has zero overhead during failure-free operation. Our approach preserves application data integrity in crash-injection experiments.|
|NVMW 2014|Coset Coding to Extend the Lifetime of Non-Volatile Memory|[link](https://dukespace.lib.duke.edu/dspace/handle/10161/9396)|Architecture(NVM)| PCM and Flash memory cells both wear out based on usage. PCM is limited in the number of writes it can sustain, and Flash in the number of Program/Erase cycles. In this talk we present a technique based on coset coding that can be used to increase the effective lifetime of non-volatile memories. We will also discuss our implementation of coset coding in a prototype Flash-based SSD.|
|NVMW 2014|Compression Architecture for Bit-write Reduction in Non-volatile Memory Technologies|[link](https://dl.acm.org/citation.cfm?id=2770300)|Architecture(NVM)Hardware|This paper describes a compression-based architecture for bit-write reduction in emerging non-volatile memories (NVMs). Bit-write reduction has many practical benefits, including lower write latency, lower dynamic energy, and enhanced endurance. The proposed architecture, which is integrated into the memory controller, relies on (i) a frequent pattern compression engine, (ii) a comparator to reduce bit-writes, and (iii) an opportunistic wear leveler to spread writes and enhance memory endurance by reducing the peak bit-writes/cell. Trace-based simulations of the SPEC CPU2006 benchmarks show a 20X reduction in raw bit-writes, which corresponds to a 2-3X improvement over the best state-of-the-art methods, and a 20% reduction in peak cell bit-writes, improving NVM lifetime.|
|NVMW 2014|LightNVM: Lightning Fast Evaluation Platform for Non-Volatile Memories|[link](https://pdfs.semanticscholar.org/30eb/bf2b42ef3a5714b0f5350f85842e3ca2e408.pdf)|Architecture(NVM)Software|We present LightNVM, an SSD evaluation platform, that is both magnitude faster of current solutions, but also presents a highly scalable engine for low-latency memory designs, such as PCM and MRAM, to evaluate novel research work, without using an expensive evaluation platform.|
|NVMW 2013|bcache: Efficient Block Caching on SSDs|[link](https://bcache.evilpiepirate.org/)|Architecture(NVM) OS Interface|We present bcache, a high performance block layer SSD cache. We\'ll briefly explore the architecture and analyze the various tradeoffs and optimizations required to make it effective in real world situations.|
|NVMW 2018|LightNVM: The Linux Open-Channel SSD Subsystem|[link](https://www.usenix.org/system/files/conference/fast17/fast17-bjorling.pdf)|Architecture(NVM)OS Interface|we describe our experience build- ing LightNVM, the Open-Channel SSD subsystem in the Linux kernel. LightNVM is the first open, generic subsys- tem for Open-Channel SSDs and host-based SSD manage- ment. We make four contributions. First, we describe the characteristics of open-channel SSD management. We iden- tify the constraints linked to exposing SSD internals, discuss the associated trade-offs and lessons learned from the storage industry. Second, we introduce the Physical Page Address (PPA) I/O interface, an interface for Open-Channel SSDs, that defines a hierarchical address space together with control and vectored data commands. Third, we present LightNVM, the Linux subsystem that we designed and implemented for open- channel SSD management. It provides an interface where application-specific abstractions, denoted as targets, can be im- plemented. We provide a host-based Flash Translation Layer, called pblk, that exposes open-channel SSDs as traditional block I/O devices. Finally, we demonstrate the effectiveness of LightNVM on top of a first generation open-channel SSD. Our results are the first measurements of an open-channel SSD that exposes the physical page address I/O interface. We compare against state-of-the-art block I/O SSD and evaluate performance overheads when running synthetic, file system, and database system-based workloads. Our results show that LightNVM achieves high performance and can be tuned to control I/O latency variability.|
|NVMW 2018|NOVA-Fortis: A Fault-Tolerant Non-Volatile Main Memory File System|[link](https://cseweb.ucsd.edu/~swanson/papers/SOSP2017-NOVAFortis.pdf)|Architecture(NVM)OS Interface|Emerging fast, persistent memories will enable systems that combine conventional DRAM with large amounts of nonvolatile main memory (NVMM) and provide huge increases in storage performance. Fully realizing this potential requires fundamental changes in how system software manages, protects, and provides access to data that resides in NVMM. We address these needs by describing an NVMM-optimized file system called NOVA-Fortis that is both fast and resilient in the face of corruption due to media errors and software bugs. We identify and propose solutions for the unique challenges in adding fault tolerance to an NVMM file system, adapt state-of-the-art reliability techniques to an NVMM file system, and quantify the performance and storage overheads of these techniques.|
|NVMW 2018|Architectural Support for Atomic Durability in Non-Volatile Memory|[link](http://homepages.inf.ed.ac.uk/s1372211/pub/nvmw18.pdf)|Architecture(NVM)Hardware|Non-volatile memory (NVM) is emerging as a fast byte-addressable alternative for storing persistent data. Ensuring atomic durability in NVM requires logging. Existing techniques have proposed software logging either by using streaming stores for an undo log; or, by relying on the combination of clflush and mfence for a redo log. These techniques are suboptimal because they waste precious execution cycles to implement logging, which is fundamentally a data movement operation. We propose ATOM, a hardware log manager based on undo logging that performs the logging operation out of the critical path. We present the design principles behind ATOM and two techniques to optimize its performance. Our results show that ATOM achieves an improvement of 27% for micro-benchmarks and 60% for TPC-C over a baseline undo log design.| 
|NVMW 2018|Accelerating Multiplication and Parallelizing Operations in Non-Volatile Memory|[link](http://nvmw.ucsd.edu/nvmw18-program/unzip/current/nvmw2018-final9.pdf)|In Memory processing|Recent years have witnessed a rapid growth in the domain of Internet of Things (IoT). This network of billions of devices generates and exchanges huge amount of data. The limited cache capacity and memory bandwidth make transferring and processing such data on traditional CPUs and GPUs highly inefficient, both in terms of energy consumption and delay. However, many IoT applications are statistical at heart and can accept a part of inaccuracy in their computation. This enables the designers to reduce complexity of processing by approximating the results for a desired accuracy. In this paper, we propose an ultra-efficient approximate processing in-memory architecture, called APIM, which exploits the analog characteristics of non-volatile memories to support addition and multiplication inside the crossbar memory, while storing the data. The proposed design eliminates the overhead involved in transferring data to processor by virtually bringing the processor inside memory. APIM dynamically configures the precision of computation for each application in order to tune the level of accuracy during runtime. Our experimental evaluation running six general OpenCL applications shows that the proposed design achieves up to 20x performance improvement and provides 480x improvement in energy-delay product, ensuring acceptable quality of service. In exact mode, it achieves 28x energy savings and 4.8x speed up compared to the state-of-the-art GPU cores.|
|ASPLOS XVI 2011|Mnemosyne: Lightweight Persistent Memory|[link](http://delivery.acm.org/10.1145/1960000/1950379/p91-volos.pdf?ip=14.139.38.123&id=1950379&acc=ACTIVE%20SERVICE&key=045416EF4DDA69D9%2E6454B2DFDB9CC807%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&__acm__=1535294699_de0345d2c38535ca4753eeca29bf649a)|Architecture(NRAM)OS Interface|New storage-class memory (SCM) technologies, such as phase-change memory, STT-RAM, and memristors, promise user-level access to non-volatile storage through regular memory instructions. These memory devices enable fast user-mode access to persistence, allowing regular in-memory data structures to survive system crashes.In this paper, we present Mnemosyne, a simple interface for programming with persistent memory. Mnemosyne addresses two challenges: how to create and manage such memory, and how to ensure consistency in the presence of failures. Without additional mechanisms, a system failure may leave data structures in SCM in an invalid state, crashing the program the next time it starts.In Mnemosyne, programmers declare global persistent data with the keyword "pstatic" or allocate it dynamically. Mnemosyne provides primitives for directly modifying persistent variables and supports consistent updates through a lightweight transaction mechanism. Compared to past work on disk-based persistent memory, Mnemosyne reduces latency to storage by writing data directly to memory at the granularity of an update rather than writing memory pages back to disk through the file system. In tests emulating the performance characteristics of forthcoming SCMs, we show that Mnemosyne can persist data as fast as 3 microseconds. Furthermore, it provides a 35 percent performance increase when applied in the OpenLDAP directory server. In microbenchmark studies we find that Mnemosyne can be up to 1400% faster than alternative persistence strategies, such as Berkeley DB or Boost serialization, that are designed for disks.

# Added on 12 December 2018

|Conference| Title   |     Link     |Broad category|  Abstract |
|:-------|:----------|:-------------:|:--------|:------|
|USENIX 2013|Exploring System Challenges of Ultra-Low Latency Solid State Drives|[link](https://www.usenix.org/system/files/conference/hotstorage18/hotstorage18-paper-koh.pdf)|SSD Performance Characterization|We quantitatively characterize performance behaviors of a real ultra-low latency (ULL) SSD archive by using a real 800GB Z-SSD prototype, and analyze systemlevel challenges that the current storage stack exhibits.|
|Symposium on Mass Storage Systems and Technologies (MSST) 2015|A Study of Application Performance with Non-Volatile Main Memory|[link](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7208275)|NVMM Performance Analysis|We present an analysis of storage application performance with non-volatile main memory (NVMM) using a hardware NVMM emulator that allows fine-grain tuning of NVMM performance parameters.|
|ASPLOS XVI 2011|NV-Heaps: making persistent objects fast and safe with next-generation, non-volatile memories|[link](https://dl.acm.org/citation.cfm?id=1950380)|Architecture(NRAM)OS Interface|We have implemented a lightweight, high-performance persistent object system called NV-heaps that provides transactional semantics while preventing these errors and providing a model for persistence that is easy to use and reason about. We implement search trees, hash tables, sparse graphs, and arrays using NV-heaps, BerkeleyDB, and Stasis. Our results show that NV-heap performance scales with thread count and that data structures implemented using NV-heaps out-perform BerkeleyDB and Stasis implementations by 32x and 244x, respectively, by avoiding the operating system and minimizing other software overheads. We also quantify the cost of enforcing the safety guarantees that NV-heaps provide and measure the costs of NV-heap primitive operations.|

# Added on 08 May 2019

|Conference| Title   |     Link     |Broad category|  Abstract |
|:-------|:----------|:-------------:|:--------|:------|
|MICRO 2013|Kiln: Closing the Performance Gap Between Systems With and Without Persistence Support|[link](https://ieeexplore.ieee.org/document/7847644)|NA|Non-volatile Memory consistency|Persistent memory is an emerging technology which allows in-memory persistent data objects to be updated at much higher throughput than when using disks as persistent storage. Previous persistent memory designs use logging or copy-on-write mechanisms to update persistent data, which unfortunately reduces the system performance to roughly half that of a native system with no persistence support. One of the great challenges in this application class is therefore how to efficiently enable atomic, consistent, and durable updates to ensure data persistence that survives application and/or system failures. Our goal is to design a persistent memory system with performance very close to that of a native system. We propose Kiln, a persistent memory design that adopts a nonvolatile cache and a nonvolatile main memory to enable atomic in-place updates without logging or copy-on-write. Our evaluation shows that Kiln can achieve 2× performance improvement compared with NVRAM-based persistent memory with write-ahead logging. In addition, our design has numerous practical advantages: a simple and intuitive abstract interface, microarchitecture-level optimizations, fast recovery from failures, and eliminating redundant writes to nonvolatile storage media.|
|MICRO 2015|Efficient persist barriers for multicores|[link](https://dl.acm.org/citation.cfm?id=2830805)|NA|Emerging non-volatile memory technologies enable fast, fine-grained persistence compared to slow block-based devices. In order to ensure consistency of persistent state, dirty cache lines need to be periodically flushed from caches and made persistent in an order specified by the persistency model. A persist barrier is one mechanism for enforcing this ordering.In this paper, we first show that current persist barrier implementations, flowing to certain ordering dependencies, add cache line flushes to the critical path. Our main contribution is an efficient persist barrier, that reduces the number of cache line ushes happening in the critical path. We evaluate our proposed persist barrier by using it to enforce two persistency models: buffered epoch persistency with programmer inserted barriers; and buffered strict persistency in bulk mode with hardware inserted barriers. Experimental evaluations using micro-benchmarks (buffered epoch persistency) and multi-threaded workloads (buffered strict persistency) show that using our persist barrier improves performance by 22% and 20% respectively over the state-of-the-art.|
|ISCA 2014|Memory persistency|[link](https://dl.acm.org/citation.cfm?id=2665712)|NA|Emerging nonvolatile memory technologies (NVRAM) promise the performance of DRAM with the persistence of disk. However, constraining NVRAM write order, necessary to ensure recovery correctness, limits NVRAM write concurrency and degrades throughput. We require new memory interfaces to minimally describe write constraints and allow high performance and high concurrency data structures. These goals strongly resemble memory consistency. Whereas memory consistency concerns the order that memory operations are observed between numerous processors, persistent memory systems must constrain the order that writes occur with respect to failure. We introduce memory persistency, a new approach to designing persistent memory interfaces, building on memory consistency. Similar to memory consistency, memory persistency models may be relaxed to improve performance. We describe the design space of memory persistency and desirable features that such a memory system requires. Finally, we introduce several memory persistency models and evaluate their ability to expose NVRAM write concurrency using two implementations of a persistent queue. Our results show that relaxed persistency models accelerate system throughput 30-fold by reducing NVRAM write constraints|
|USENIX ATC 2018|Redesigning LSMs for Nonvolatile Memory with NoveLSM|[link](https://www.usenix.org/conference/atc18/presentation/kannan)|NA|We present NoveLSM, a persistent LSM-based key-value storage system designed to exploit non-volatile memories and deliver low latency and high throughput to applications. We utilize three key techniques – a byte- addressable skip list, direct mutability of persistent state, and opportunistic read parallelism – to deliver high performance across a range of workload scenarios. Our analysis with popular benchmarks and real-world workload reveal up to a 3.8x and 2x reduction in write and read access latency compared to LevelDB. Storing all the data in a persistent skip list and avoiding block I/O provides more than 5x and 1.9x higher write throughput over LevelDB and RocksDB. Recovery time improves substantially with NoveLSM’s persistent skip list.|
|USENIX OSDI 2018|Write-Optimized and High-Performance Hashing Index Scheme for Persistent Memory|[link](https://www.usenix.org/system/files/osdi18-zuo.pdf)|NA|Non-volatile memory (NVM) as persistent memory is expected to substitute or complement DRAM in memory hierarchy, due to the strengths of non-volatility, high density, and near-zero standby power. However, due to the requirement of data consistency and hardware limitations of NVM, traditional indexing techniques originally designed for DRAM become inefficient in persistent memory. To efficiently index the data in persistent memory, this paper proposes a write-optimized and high-performance hashing index scheme, called level hashing, with low-overhead consistency guarantee and cost-efficient resizing. Level hashing provides a sharing-based two-level hash table, which achieves a constant-scale search/insertion/deletion/update time complexity in the worst case and rarely incurs extra NVM writes. To guarantee the consistency with low overhead, level hashing leverages log-free consistency schemes for insertion, deletion, and resizing operations, and an opportunistic log-free scheme for update operation. To cost-efficiently resize this hash table, level hashing leverages an in-place resizing scheme that only needs to rehash $1/3$ of buckets instead of the entire table, thus significantly reducing the number of rehashed buckets and improving the resizing performance.|
|MCHPC 2018|Understanding Application Recomputability without Crash Consistency in Non-Volatile Memory|[link](http://pasa.ucmerced.edu/wp-content/uploads/2018/09/Understanding_Application.pdf)|NA|Emerging non-volatile memory (NVM) is promising to be used as main memory, because of its good performance, density, and energy efficiency. Leveraging the non-volatility of NVM as main memory, we can recover data objects and resume application computation (recomputation) after the application crashes. The existing work studies how to ensure that data objects stored in NVM can be recovered to a consistent version during system recovery, a property referred to as crash consistency. However, enabling crash consistency often requires program modification and brings large runtime overhead.In this paper, we use a different view to examine application recomputation in NVM. Without taking care of consistency of data objects, we aim to understand if the application can be recomputable, given possible inconsistent data objects in NVM. We introduce a PIN-based simulation tool, NVC, to study application recomputability in NVM without crash consistency. The tool allows the user to randomly trigger application crash and then perform postmortem analysis on data values in caches and memory to examine data consistency. We use NVC to study a set of applications. We reveal that some applications are inherently tolerant to the data inconsistency problem. We perform a detailed analysis of application recomputability without crash consistency in NVM.
|MICRO 2018|PiCL: a Software-Transparent, Persistent Cache Log for Nonvolatile Main Memory|[link](http://parallel.princeton.edu/papers/micro18-nguyen-picl.pdf)|NA|—Software-transparent crash consistency is a promising direction to immediately reap the benefits of nonvolatile main memory (NVMM) without encumbering programmers with errorprone transactional semantics. Unfortunately, proposed hardware write-ahead logging (WAL) schemes have high performance overhead, particularly for multi-core systems with many threads and big on-chip caches and NVMs with low random-access performance. This paper proposes PiCL, a new WAL checkpointing mechanism that provides a low overhead, software-transparent crash consistency solution for NVMM. PiCL introduces multiundo logging, cache-driven logging, and asynchronous cache-scan to reduce random accesses and enable good row locality at the NVM. The key idea is that: by relaxing the durability timing of checkpoints, crash consistency can be provided with less than 1% performance overhead where 1.5× to 5.0× slowdown was typical with prior work. To demonstrate the feasibility of softwaretransparent crash consistency, we fully implemented PiCL as an FPGA prototype in Verilog using the OpenPiton framework.|
|MICRO 2015|ThyNVM: Enabling Software-Transparent Crash Consistency in Persistent Memory Systems|[link](https://ieeexplore.ieee.org/document/7856636)|NA|Emerging byte-addressable nonvolatile memories (NVMs) promise persistent memory, which allows processors to directly access persistent data in main memory. Yet, persistent memory systems need to guarantee a consistent memory state in the event of power loss or a system crash (i.e., crash consistency). To guarantee crash consistency, most prior works rely on programmers to (1) partition persistent and transient memory data and (2) use specialized software interfaces when updating persistent memory data. As a result, taking advantage of persistent memory requires significant programmer effort, e.g., to implement new programs as well as modify legacy programs. Use cases and adoption of persistent memory can therefore be largely limited. In this paper, we propose a hardware-assisted DRAM+NVM hybrid persistent memory design, Transparent Hybrid NVM (ThyNVM), which supports software-transparent crash consistency of memory data in a hybrid memory system. To efficiently enforce crash consistency, we design a new dual-scheme checkpointing mechanism, which efficiently overlaps checkpointing time with application execution time. The key novelty is to enable checkpointing of data at multiple granularities, cache block or page granularity, in a coordinated manner. This design is based on our insight that there is a tradeoff between the application stall time due to checkpointing and the hardware storage overhead of the metadata for checkpointing, both of which are dictated by the granularity of checkpointed data. To get the best of the tradeoff, our technique adapts the checkpointing granularity to the write locality characteristics of the data and coordinates the management of multiple-granularity updates. Our evaluation across a variety of applications shows that ThyNVM performs within 4.9% of an idealized DRAM-only system that can provide crash consistency at no cost.|
|HPCA 2017|ATOM: Atomic Durability in Non-volatile Memory through Hardware Logging|[link](https://ieeexplore.ieee.org/document/7920839)|NA|Non-volatile memory (NVM) is emerging as a fast byte-addressable alternative for storing persistent data. Ensuring atomic durability in NVM requires logging. Existing techniques have proposed software logging either by using streaming stores for an undo log; or, by relying on the combination of clflush and mfence for a redo log. These techniques are suboptimal because they waste precious execution cycles to implement logging, which is fundamentally a data movement operation. We propose ATOM, a hardware log manager based on undo logging that performs the logging operation out of the critical path. We present the design principles behind ATOM and two techniques to optimize its performance. Our results show that ATOM achieves an improvement of 27% to 33% for micro-benchmarks and 60% for TPC-C over a baseline undo log design.|
|VLDB 2015|REWIND: Recovery Write-Ahead System for In-Memory Non-Volatile Data-Structures|[link](https://dl.acm.org/citation.cfm?id=2735483)|NA|Recent non-volatile memory (NVM) technologies, such as PCM, STT-MRAM and ReRAM, can act as both main memory and storage. This has led to research into NVM programming models, where persistent data structures remain in memory and are accessed directly through CPU loads and stores. Existing mechanisms for transactional updates are not appropriate in such a setting as they are optimized for block-based storage. We present REWIND, a user-mode library approach to managing transactional updates directly from user code written in an imperative general-purpose language. REWIND relies on a custom persistent in-memory data structure for the log that supports recoverable operations on itself. The scheme also employs a combination of non-temporal updates, persistent memory fences, and lightweight logging. Experimental results on synthetic transactional workloads and TPC-C show the overhead of REWIND compared to its non-recoverable equivalent to be within a factor of only 1.5 and 1.39 respectively. Moreover, REWIND outperforms state-of-the-art approaches for data structure recoverability as well as general purpose and NVM-aware DBMS-based recovery schemes by up to two orders of magnitude.|