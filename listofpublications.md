# Papers related to NVRAM
--------------------------------------------------

|Conference| Title   |     Link     |Broad category|  Abstract |
|:-------|:----------|:-------------:|:--------|:------|
|ISCA 2014| A low power and reliable charge pump design for Phase Change Memories |  [link](https://ieeexplore.ieee.org/document/6853222/) |NVRAM write ordering for memory persistency |Emerging nonvolatile memory technologies (NVRAM) promise the performance of DRAM with the persistence of disk. However, constraining NVRAM write order, necessary to ensure recovery correctness, limits NVRAM write concurrency and degrades throughput. We require new memory interfaces to minimally describe write constraints and allow high performance and high concurrency data structures. These goals strongly resemble memory consistency. Whereas memory consistency concerns the order that memory operations are observed between numerous processors, persistent memory systems must constrain the order that writes occur with respect to failure. We introduce memory persistency, a new approach to designing persistent memory interfaces, building on memory consistency. Similar to memory consistency, memory persistency models may be relaxed to improve performance. We describe the design space of memory persistency and desirable features that such a memory system requires. Finally, we introduce several memory persistency models and evaluate their ability to expose NVRAM write concurrency using two implementations of a persistent queue. Our results show that relaxed persistency models accelerate system throughput 30-fold by reducing NVRAM write constraints.|
|ISCA 2017|Viyojit: Decoupling battery and DRAM capacities for battery-backed DRAM|[link](https://ieeexplore.ieee.org/document/8192506/)| Solution to the battery scaling problem for battery-backed DRAM|Non-Volatile Memories (NVMs) can significantly improve the performance of data-intensive applications. A popular form of NVM is Battery-backed DRAM, which is available and in use today with DRAMs latency and without the endurance problems of emerging NVM technologies. Modern servers can be provisioned with up-to 4 TB of DRAM, and provisioning battery backup to write out such large memories is hard because of the large battery sizes and the added hardware and cooling costs. We present Viyojit, a system that exploits the skew in write working sets of applications to provision substantially smaller batteries while still ensuring durability for the entire DRAM capacity. Viyojit achieves this by bounding the number of dirty pages in DRAM based on the provisioned battery capacity and proactively writing out infrequently written pages to an SSD. Even for write-heavy workloads with less skew than we observe in analysis of real data center traces, Viyojit reduces the required battery capacity to 11% of the original size, with a performance overhead of 7-25%. Thus, Viyojit frees battery-backed DRAM from stunted growth of battery capacities and enables servers with terabytes of battery-backed DRAM.|
|ISCA 2018| 2B-SSD: The Case for Dual, Byte- and Block-Addressable Solid-State Drives |[link](https://ieeexplore.ieee.org/document/8416845/)|Software interface for byte and block I/O|Performance critical transaction and storage systems require fast persistence of write data. Typically, a non-volatile RAM (NVRAM) is employed on the datapath to the permanent storage, to temporarily and quickly store write data before the system acknowledges the write request. NVRAM is commonly implemented with battery-backed DRAM. Unfortunately, battery-backed DRAM is small and costly, and occupies a precious DIMM slot. In this paper, we make a case for dual, byte- and block-addressable solid-state drive (2B-SSD), a novel NAND flash SSD architecture designed to offer a dual view of byte addressability and traditional block addressability at the same time. Unlike a conventional storage device, 2B-SSD allows accessing the same file with two independent byte- and block-I/O paths. It controls the data transfer between its internal DRAM and NAND flash memory through an intuitive software interface, and manages the mapping of the two address spaces. 2B-SSD realizes a wholly different way and speed of accessing files on a storage device; applications can access them directly using memory-mapped I/O, and moreover write with a DRAM-like latency. To quantify the benefits of 2B-SSD, we modified logging subsystems of major database engines to store log records directly on it without buffering them in the host memory. When running popular workloads, we measured throughput gains in the range of 1.2X and 2.8X with no risk of data loss.|
|MICRO 2014|FIRM: Fair and High-Performance Memory Control for Persistent Memory Systems|[link](https://ieeexplore.ieee.org/document/7011385/) |Memory control scheme for a persistent memory|Byte-addressable nonvolatile memories promise a new technology, persistent memory, which incorporates desirable attributes from both traditional main memory (byte-addressability and fast interface) and traditional storage (data persistence). To support data persistence, a persistent memory system requires sophisticated data duplication and ordering control for write requests. As a result, applications that manipulate persistent memory (persistent applications) have very different memory access characteristics than traditional (non-persistent) applications, as shown in this paper. Persistent applications introduce heavy write traffic to contiguous memory regions at a memory channel, which cannot concurrently service read and write requests, leading to memory bandwidth underutilization due to low bank-level parallelism, frequent write queue drains, and frequent bus turnarounds between reads and writes. These characteristics undermine the high-performance and fairness offered by conventional memory scheduling schemes designed for non-persistent applications. Our goal in this paper is to design a fair and high-performance memory control scheme for a persistent memory based system that runs both persistent and non-persistent applications. Our proposal, FIRM, consists of three key ideas. First, FIRM categorizes request sources as non-intensive, streaming, random and persistent, and forms batches of requests for each source. Second, FIRM strides persistent memory updates across multiple banks, thereby improving bank-level parallelism and hence memory bandwidth utilization of persistent memory accesses. Third, FIRM schedules read and write request batches from different sources in a manner that minimizes bus turnarounds and write queue drains. Our detailed evaluations show that, compared to five previous memory scheduler designs, FIRM provides significantly higher system performance and fairness.|
|HPCA 2018|Crash Consistency in Encrypted Non-volatile Main Memory Systems| [link](https://ieeexplore.ieee.org/document/8327018/)|Crash consistency mechanisms and memory encryption|Non-Volatile Main Memory (NVMM) systems provide high performance by directly manipulating persistent data in-memory, but require crash consistency support to recover data in a consistent state in case of a power failure or system crash. In this work, we focus on the interplay between the crash consistency mechanisms and memory encryption. Memory encryption is necessary for these systems to protect data against the attackers with physical access to the persistent main memory. As decrypting data at every memory read access can significantly degrade the performance, prior works propose to use a memory encryption technique, counter-mode encryption, that reduces the decryption overhead by performing a memory read access in parallel with the decryption process using a counter associated with each cache line. Therefore, a pair of data and counter value is needed to correctly decrypt data after a system crash. We demonstrate that counter-mode encryption does not readily extend to crash consistent NVMM systems as the system will fail to recover data in a consistent state if the encrypted data and associated counter are not written back to memory atomically, a requirement we refer to as counter-atomicity. We show that naively enforcing counter-atomicity for all NVMM writes can serialize memory accesses and results in a significant performance degradation. In order to improve the performance, we make an observation that not all writes to NVMM need to be counter-atomic. The crash consistency mechanisms rely on versioning to keep one consistent copy of data intact while manipulating another version directly in-memory. As the recovery process only relies on the unmodified consistent version, it is not necessary to strictly enforce counter-atomicity for the writes that do not affect data recovery. Based on this insight, we propose selective counter-atomicity that allows reordering of writes to data and associated counters when the writes to persistent memory do not alter the recoverable consistent state. We propose efficient software and hardware support to enforce selective counter-atomicity. Our evaluation demonstrates that in a 1/2/4/8- core system, selective counter-atomicity improves performance by 6/11/22/40% compared to a system that enforces counter-atomicity for all NVMM writes. The performance of our selective counter-atomicity design comes within 5% of an ideal NVMM system that |provides crash consistency of encrypted data at no cost.|
|HPCA 2016|Atomic persistence for SCM with a non-intrusive backend controller|[link](https://ieeexplore.ieee.org/document/7446055/)|Backend controller and a software library for failure atomicity|Non-volatile byte-addressable memory has the potential to revolutionize system architecture by providing instruction-grained direct access to vast amounts of persistent data. We describe a non-intrusive memory controller that uses backend operations for achieving lightweight failure atomicity. By moving synchronous persistent memory operations to the background, the performance overheads are minimized. Our solution avoids costly software intervention by decoupling isolation and concurrency-driven atomicity from failure atomicity and durability, and does not require changes to the front-end cache hierarchy. Two implementation alternatives - one using a hardware structure, and the other extending the memory controller with a firmware managed volatile space - are described. Our results show the performance is significantly better than traditional approaches.|
|ASPLOS '16| NVWAL: Exploiting NVRAM in Write-Ahead Logging|[link](https://dl.acm.org/citation.cfm?id=2872392)|NVRAM Write-Ahead Logging for SQLite| Emerging byte-addressable non-volatile memory is considered an alternative storage device for database logs that require persistency and high performance. In this work, we develop NVWAL (NVRAM Write-Ahead Logging) for SQLite. The contribution of NVWAL consists of three elements: (i) byte-granularity differential logging that effectively eliminates the excessive I/O overhead of filesystem-based logging or journaling, (ii) transaction-aware lazy synchronization that reduces cache synchronization overhead by two-thirds, and (iii) user-level heap management of the NVRAM persistent WAL structure, which reduces the overhead of managing persistent objects. We implemented NVWAL in SQLite and measured the performance on a Nexus 5 smartphone and an NVRAM emulation board - Tuna. Our performance study shows the following: (i) the overhead of enforcing strict ordering of NVRAM writes can be reduced via NVRAM-aware transaction management. (ii) From the application performance point of view, the overhead of guaranteeing failure atomicity is negligible; the cache line flush overhead accounts for only 0.8~4.6% of transaction execution time. Therefore, application performance is much less sensitive to the NVRAM performance than we expected. Decreasing the NVRAM latency by one-fifth (from 1942 nsec to 437 nsec), SQLite achieves a mere 4% performance gain (from 2517 ins/sec to 2621 ins/sec). (iii) Overall, when the write latency of NVRAM is 2 usec, NVWAL increases SQLite performance by at least 10x compared to that of WAL on flash memory (from 541 ins/sec to 5812 ins/sec).|
|DAC 18| Enabling union page cache to boost file access performance of NVRAM-based storage device| [link](https://dl.acm.org/citation.cfm?id=3196045)|Remove unnecessary data movements by jointly managing data of page cache in both main memory and storage.|Due to the fast access performance, byte-addressability, and non-volatility of non-volatile random access memory (NVRAM), NVRAM has emerged as a popular candidate for the design of memory/storage systems on mobile computing systems. For example, the latest 3D xPoint memory could be a kind of NVRAM with much longer life expectancy than NAND flash and could ease the possible endurance issue. When NVRAM is considered as both main memory and storage in mobile computing systems, existing page cache mechanisms introduce too many unnecessary data movements between main memory and storage. To resolve this issue, we propose the concept of "union page cache," which jointly manages data of the page cache in both main memory and storage. To realize this concept, a partial page cache strategy is designed to consider both main memory and storage as its management space and to eliminate unnecessary data movements between main memory and storage without sacrificing the data consistency of file systems. Experimental results show that the proposed strategy can boost the file accessing performance upto 85.62% when using PCM as a case study.|
|IEEE Transactions on Parallel and Distributed Systems|Building NVRAM-Aware Swapping Through Code Migration in Mobile Devices|[link](https://ieeexplore.ieee.org/abstract/document/7944530/)|Prolonging the lifetime of NVRAM based swap area|Mobile applications are becoming increasingly feature-rich and powerful, but also dependent on large main memories, which consume a large portion of system energy, especially for devices equipped with 4/6 GB DRAM. Swapping inactive DRAM pages to byte-addressable, non-volatile memory (NVRAM) is a promising solution to this problem. However, most NVRAMs have limited write endurance and the current victim pages selecting algorithm does not aware it. Therefore, to make it practical, the design of an NVRAM based swapping system must also consider endurance. In this paper, we target at prolonging the lifetime of NVRAM based swap area in mobile devices by reducing the write activities to NVRAM based swap area. Different from traditional wisdom, such as wear leveling and hot/cold data identification, we propose to build a system called nCode, which exploits the fact that code pages are easy to identify, read-only, and therefore a perfect candidate for swapping. Utilizing NVRAM's byte-addressability, we support execute-in-place (XIP) of the code pages in the swap area, without copying them back to DRAM based main memory. Experimental results based on the Google Nexus 5 smartphone show that nCode can effectively prolong the lifetime of NVRAM under various workloads.|
|VLDB 2015|nvm malloc: Memory Allocation for NVRAM|[link](http://www.adms-conf.org/2015/adms15_schwalb.pdf)|General-purpose memory allocator for NVRAM|Non-volatile main memory (NVRAM) has the potential to fundamentally change the persistency of software. Applications can make their state persistent by directly placing data structures on NVRAM instead of volatile DRAM. However, the persistent nature of NVRAM requires significant changes for memory allocators that are now faced with the additional tasks of data recovery and failure-atomicity. In this paper, we present nvm malloc, a general-purpose memory allocator concept for the NVRAM era as a basic building block for persistent applications. We introduce concepts for managing named allocations for simplified recovery and using volatile and non-volatile memory in combination to provide both high performance and failure-atomic allocations.|
|IEEE Transactions on Consumer Electronics(2012)|Efficient logging of metadata using NVRAM for NAND flash based file system|[link](https://ieeexplore.ieee.org/abstract/document/6170059/)|NAND flash file system|In this work, we designed and implemented schemes that defer writing of metadata in order to realize an efficient and reliable NAND flash file system. The conventional NAND flash file systems synchronously write their metadata in the NAND flash for reliability; however, the synchronous writing of metadata generates excessive garbage. We propose the scheme for merging the writing of metadata so as to reduce the garbage of the NAND flash while ensuring file system consistency. The proposed scheme uses the non-volatile memory for synchronously logging modifications of the metadata. The logging can significantly reduce excessive metadata writing of NAND flash. Also, the last modified metadata can be recovered from a crash, after scanning logs in the non-volatile memory. We implemented the scheme for the deferred writing of metadata on top of a Linux OS. The evaluation results show that the proposed scheme greatly reduced the overall application time and the number of written pages across various benchmarks, compared to the conventional flash file system.|
|NVMW 17|SECRET: Smartly EnCRypted Energy EfficienT Non-Volatile Memories|[link](https://ieeexplore.ieee.org/document/7544407/)|Data Encryption|Data persistence in emerging non-volatile memories (NVMs) poses a multitude of security vulnerabilities, motivating main memory encryption for data security. However, practical encryption algorithms demonstrate strong diffusion characteristics that increase cell flips, resulting in increased write energy/latency and reduced lifetime of NVMs. State-of-the-art security solutions have focused on reducing the encryption penalty (increased write energy/latency and reduced memory lifetime) in single-level cell (SLC) NVMs; however, the realization of low encryption penalty solutions for multi-/triple-level cell (MLC/TLC) secure NVMs remains an open area of research. This work synergistically integrates zero-based partial writes with XOR-based energy masking to realize Smartly EnCRypted Energy efficienT, i.e., SECRET MLC/TLC NVMs, without compromising the security of the underlying encryption technique. Our simulations on an MLC (TLC) resistive RAM (RRAM) architecture across SPEC CPU2006 workloads demonstrate that for 6.25% (7.84%) memory overhead, SECRET reduces write energy by 80% (63%), latency by 37% (49%), and improves memory lifetime by 63% (56%) over conventional advanced encryption standard-based (AES-based) counter mode encryption.|
|NVMW 17|NVQuery: Efficient Query Processing in Non-Volatile Memory|[link](https://ieeexplore.ieee.org/document/8323230/)|Non-volatile memory-based query accelerator,in memory processing|Today’s computing systems use huge amount of energy and time to process basic queries in database. A large part of it is spent in data movement between the memory and processing cores, owing to the limited cache capacity and memory bandwidth of traditional computers. In this paper, we propose a non-volatile memory-based query accelerator, called NVQuery, which performs several basic query functions in memory including aggregation, prediction, bit-wise operations, join operations, as well as exact and nearest distance search queries. NVQuery is implemented on a content addressable memory (CAM) and exploits the analog characteristic of non-volatile memory in order to enable in-memory processing. To implement nearest distance search in memory, we introduce a novel bitline driving scheme to give weights to the indices of the bits during the search operation. To further improve the energy efficiency, our design supports configurable approximation by adaptively putting memory blocks under voltage overscaling. Our experimental evaluation shows that, NVQuery can provide 49.3× performance speedup and 32.9× energy savings as compared to running the same query on traditional processor. Approximation improves the energy-delay product of NVQuery by 7.3×, while providing acceptable accuracy. In addition, NVQuery can achieve 30.1× energy-delay product improvement as compared to the state-of-the-art query accelerators.|
|NVMW 16|NOVA: A Log-structured File System for Hybrid Volatile/Non-volatile Main Memories|[link](https://www.usenix.org/system/files/conference/fast16/fast16-papers-xu.pdf)|File systems for NVMs|NOVA is a log-structured file system for hybrid volatile/non-volatile main memories. NOVA extends LFS to leverage NVMM, yielding a simpler, high-performance file system that supports fast and efficient garbage collection and quick recovery from system failures. NOVA outperforms existing file systems by a wide margin on a wide range of applications while providing stronger consistency and atomicity guarantees.|
|FAST 15|NV-Tree: Reducing Consistency Cost for NVM-based Single Level Systems|[link](https://www.usenix.org/conference/fast15/technical-sessions/presentation/yang)|Consistent and cache-optimized B+Tree variant with reduced CPU cacheline flush|The non-volatile memory (NVM) has DRAM-like performance and disk-like persistency which make it possible to replace both disk and DRAM to build single level systems. To keep data consistency in such systems is non-trivial because memory writes may be reordered by CPU and memory controller. In this paper, we study the consistency cost for an important and common data structure, B+Tree. Although the memory fence and CPU cacheline flush instructions can order memory writes to achieve data consistency, they introduce a significant overhead (more than 10X slower in performance). Based on our quantitative analysis of consistency cost, we propose NV-Tree, a consistent and cache-optimized B+Tree variant with reduced CPU cacheline flush. We implement and evaluate NV-Tree and NV-Store, a key-value store based on NV-Tree, on an NVDIMM server. NVTree outperforms the state-of-art consistent tree structures by up to 12X under write-intensive workloads. NV-Store increases the throughput by up to 4.8X under YCSB workloads compared to Redis.|
|DAC 2017|A Novel ReRAM-Based Main Memory Structure for Optimizing Access Latency and Reliability|[link](https://dl.acm.org/citation.cfm?id=3062191)|ReRAM-based main memory structure|Emerging Resistive Memory (ReRAM) is a promising candidate as the replacement for DRAM because of its low power consumption, high density and high endurance. Due to the unique crossbar structure, ReRAM can be constructed with a very high density. However, ReRAM's crossbar structure causes an IR drop problem which results in non-uniform access latency in ReRAM banks and reduces its reliability. Besides, the access latency and reliability of ReRAM arrays are greatly influenced by the data patterns involved in a write operation. In this paper, we propose a performance and reliability efficient ReRAM-based main memory structure. At the circuit level, we propose a double-sided write driver design to reduce the IR drops along bitlines. At the architecture level, a region partition with address remapping method and two flip schemes are proposed to reduce the access latency and improve the reliability of ReRAM arrays. The experimental results show that the proposed design can improve the system performance by 30.3% on average and reduce the memory access latency by 25.9% on average over an aggressive baseline, meanwhile the design improves the reliability of ReRAM-based memory system.|
|DAC 2016|Fine-Granularity Tile-Level Parallelism in Non-volatile Memory Architecture with Two-Dimensional Bank Subdivision|[link](https://ieeexplore.ieee.org/document/7544409/)|Design a finegrained non-volatile memory|Emerging memory technologies such as phase-change memory (PCM) and resistive RAMs (RRAM) have been proposed as promising candidates for future DRAM replacements. Due to the nature of how these memories operate, unique properties (such as non-destructive read and current-sensing) can be exploited to further subdivide memory and provide increasing parallelism with negligible overhead. In this work, we leverage these properties to design a finegrained non-volatile memory (FgNVM), featuring two-dimensional bank subdivision for tile-level parallelism (TLP) in a NVM memory bank, with much finer-granularity and increased parallelism than the one-dimensional bank subdivision for subarray-level parallelism (SALP) in a DRAM memory bank. With such new tile-level parallelism, three new memory access modes are proposed for further performance improvement and energy reduction: Partial-Activation, Multi-Activation, and Background Writes. Our experimental results show that the new architecture is highly effective in boosting non-volatile memory performance with significant energy reduction. To the best of our knowledge, this is the first work to study fine-granularity memory access in emerging non-volatile memory architectures.|
|DAC 2016|Pinatubo: A processing-in-memory architecture for bulk bitwise operations in emerging non-volatile memories|[link](https://ieeexplore.ieee.org/document/7544414/)|Processing-in-memory|Processing-in-memory (PIM) provides high bandwidth, massive parallelism, and high energy efficiency by implementing computations in main memory, therefore eliminating the overhead of data movement between CPU and memory. While most of the recent work focused on PIM in DRAM memory with 3D die-stacking technology, we propose to leverage the unique features of emerging non-volatile memory (NVM), such as resistance-based storage and current sensing, to enable efficient PIM design in NVM. We propose Pinatubo 1 , a Processing In Non-volatile memory ArchiTecture for bUlk Bitwise Operations. Instead of integrating complex logic inside the cost-sensitive memory, Pinatubo redesigns the read circuitry so that it can compute the bitwise logic of two or more memory rows very efficiently, and support one-step multi-row operations. The experimental results on data intensive graph processing and database applications show that Pinatubo achieves a ~500 x speedup, ~28000x energy saving on bitwise operations, and 1.12× overall speedup, 1.11× overall energy saving over the conventional processor.|
|NVMW 2015|Rethinking the Memory Hierarchy Design with Nonvolatile Memories|[link](https://etda.libraries.psu.edu/files/final_submissions/9564)|Bandwidth-aware reconfigurable cache hierarchy with hybrid memory technologies|NVMs promise new persistent memory technology, which combines attractive attributes from both main memory (fast, load/store interface) and storage (data persistence). Unfortunately, supporting persistence in the memory can incur significant performance overheads; the well-studied memory hierarchy design is no longer well-suited to this new scenario. This talk will show our work on optimizing the performance of persistent memory systems with new memory control schemes and memory hierarchy design.|
|NVMW 2015|A Reliable and Highly-Available Non-Volatile Memory System|[link](http://cseweb.ucsd.edu/~yiyingzhang/mojim-asplos15.pdf)|Large-scale storage systems using non-volatile memories|Next-generation non-volatile memories can attach directly to processors to form non-volatile main memory (NVMM) and offer the opportunity to build very low latency storage systems. However, providing reliability and availability to NVMM is challenging, since the latency of data replication can squander the low latency that NVMM can provide. We propose Mojim, a system that provides the reliability and availability that large-scale storage systems require, while preserving the performance of NVMM.|
|NVMW 2015|Zero-Overhead NVM Crash Resilience|[link](https://pdfs.semanticscholar.org/50f2/83259801ffbd354aaf94228d3b48c19ee6ed.pdf)|NVM-style programming|Byte-addressable non-volatile memory (NVM) allows in-place update of durable data. NVM transaction mechanisms prevent failures during updates from corrupting data, but such mechanisms carry substantial performance overheads. Our new alternative for high-performance multi-threaded software guarantees consistent recovery of application data following failure and has zero overhead during failure-free operation. Our approach preserves application data integrity in crash-injection experiments.|
|NVMW 2014|Coset Coding to Extend the Lifetime of Non-Volatile Memory|[link](https://dukespace.lib.duke.edu/dspace/handle/10161/9396)|Increase the lifetime of memory locations| PCM and Flash memory cells both wear out based on usage. PCM is limited in the number of writes it can sustain, and Flash in the number of Program/Erase cycles. In this talk we present a technique based on coset coding that can be used to increase the effective lifetime of non-volatile memories. We will also discuss our implementation of coset coding in a prototype Flash-based SSD.|
|NVMW 2014|Compression Architecture for Bit-write Reduction in Non-volatile Memory Technologies|[link](https://dl.acm.org/citation.cfm?id=2770300)|Lower Write Latency and Dynamic Energy|This paper describes a compression-based architecture for bit-write reduction in emerging non-volatile memories (NVMs). Bit-write reduction has many practical benefits, including lower write latency, lower dynamic energy, and enhanced endurance. The proposed architecture, which is integrated into the memory controller, relies on (i) a frequent pattern compression engine, (ii) a comparator to reduce bit-writes, and (iii) an opportunistic wear leveler to spread writes and enhance memory endurance by reducing the peak bit-writes/cell. Trace-based simulations of the SPEC CPU2006 benchmarks show a 20X reduction in raw bit-writes, which corresponds to a 2-3X improvement over the best state-of-the-art methods, and a 20% reduction in peak cell bit-writes, improving NVM lifetime.|
|NVMW 2014|LightNVM: Lightning Fast Evaluation Platform for Non-Volatile Memories|[link](https://pdfs.semanticscholar.org/30eb/bf2b42ef3a5714b0f5350f85842e3ca2e408.pdf)|SSD evaluation platform|We present LightNVM, an SSD evaluation platform, that is both magnitude faster of current solutions, but also presents a highly scalable engine for low-latency memory designs, such as PCM and MRAM, to evaluate novel research work, without using an expensive evaluation platform.|
|NVMW 2013|bcache: Efficient Block Caching on SSDs|[link](https://bcache.evilpiepirate.org/)|High performance copy on write filesystem|We present bcache, a high performance block layer SSD cache. We\'ll briefly explore the architecture and analyze the various tradeoffs and optimizations required to make it effective in real world situations.|
|NVMW 2018|LightNVM: The Linux Open-Channel SSD Subsystem|[link](https://www.usenix.org/system/files/conference/fast17/fast17-bjorling.pdf)|Host-based Flash Translation Layer|we describe our experience build- ing LightNVM, the Open-Channel SSD subsystem in the Linux kernel. LightNVM is the first open, generic subsys- tem for Open-Channel SSDs and host-based SSD manage- ment. We make four contributions. First, we describe the characteristics of open-channel SSD management. We iden- tify the constraints linked to exposing SSD internals, discuss the associated trade-offs and lessons learned from the storage industry. Second, we introduce the Physical Page Address (PPA) I/O interface, an interface for Open-Channel SSDs, that defines a hierarchical address space together with control and vectored data commands. Third, we present LightNVM, the Linux subsystem that we designed and implemented for open- channel SSD management. It provides an interface where application-specific abstractions, denoted as targets, can be im- plemented. We provide a host-based Flash Translation Layer, called pblk, that exposes open-channel SSDs as traditional block I/O devices. Finally, we demonstrate the effectiveness of LightNVM on top of a first generation open-channel SSD. Our results are the first measurements of an open-channel SSD that exposes the physical page address I/O interface. We compare against state-of-the-art block I/O SSD and evaluate performance overheads when running synthetic, file system, and database system-based workloads. Our results show that LightNVM achieves high performance and can be tuned to control I/O latency variability.|
|NVMW 2018|NOVA-Fortis: A Fault-Tolerant Non-Volatile Main Memory File System|[link](https://cseweb.ucsd.edu/~swanson/papers/SOSP2017-NOVAFortis.pdf)|NVMM-optimized file system|Emerging fast, persistent memories will enable systems that combine conventional DRAM with large amounts of nonvolatile main memory (NVMM) and provide huge increases in storage performance. Fully realizing this potential requires fundamental changes in how system software manages, protects, and provides access to data that resides in NVMM. We address these needs by describing an NVMM-optimized file system called NOVA-Fortis that is both fast and resilient in the face of corruption due to media errors and software bugs. We identify and propose solutions for the unique challenges in adding fault tolerance to an NVMM file system, adapt state-of-the-art reliability techniques to an NVMM file system, and quantify the performance and storage overheads of these techniques.|
|NVMW 2018|Architectural Support for Atomic Durability in Non-Volatile Memory|[link](http://homepages.inf.ed.ac.uk/s1372211/pub/nvmw18.pdf)|Hardware log manager|Non-volatile memory (NVM) is emerging as a fast byte-addressable alternative for storing persistent data. Ensuring atomic durability in NVM requires logging. Existing techniques have proposed software logging either by using streaming stores for an undo log; or, by relying on the combination of clflush and mfence for a redo log. These techniques are suboptimal because they waste precious execution cycles to implement logging, which is fundamentally a data movement operation. We propose ATOM, a hardware log manager based on undo logging that performs the logging operation out of the critical path. We present the design principles behind ATOM and two techniques to optimize its performance. Our results show that ATOM achieves an improvement of 27% for micro-benchmarks and 60% for TPC-C over a baseline undo log design.| 
|NVMW 2018|Accelerating Multiplication and Parallelizing Operations in Non-Volatile Memory|[link](http://nvmw.ucsd.edu/nvmw18-program/unzip/current/nvmw2018-final9.pdf)|Processing in-memory architecture|Recent years have witnessed a rapid growth in the domain of Internet of Things (IoT). This network of billions of devices generates and exchanges huge amount of data. The limited cache capacity and memory bandwidth make transferring and processing such data on traditional CPUs and GPUs highly inefficient, both in terms of energy consumption and delay. However, many IoT applications are statistical at heart and can accept a part of inaccuracy in their computation. This enables the designers to reduce complexity of processing by approximating the results for a desired accuracy. In this paper, we propose an ultra-efficient approximate processing in-memory architecture, called APIM, which exploits the analog characteristics of non-volatile memories to support addition and multiplication inside the crossbar memory, while storing the data. The proposed design eliminates the overhead involved in transferring data to processor by virtually bringing the processor inside memory. APIM dynamically configures the precision of computation for each application in order to tune the level of accuracy during runtime. Our experimental evaluation running six general OpenCL applications shows that the proposed design achieves up to 20x performance improvement and provides 480x improvement in energy-delay product, ensuring acceptable quality of service. In exact mode, it achieves 28x energy savings and 4.8x speed up compared to the state-of-the-art GPU cores.|

